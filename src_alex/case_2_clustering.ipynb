{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb5fc65",
   "metadata": {},
   "source": [
    "# Case 2 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce0fdf",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83fa95b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a0d35",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "054ec392",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../case_2/data/HR_data.csv'\n",
    "\n",
    "data_pd = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78107029",
   "metadata": {},
   "source": [
    "### Preproccessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bf639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, features_to_use):\n",
    "    \"\"\"\n",
    "    Preprocess the data for clustering\n",
    "    \"\"\"\n",
    "    # Select relevant features\n",
    "    X = df[features_to_use].copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85009937",
   "metadata": {},
   "source": [
    "## Clustering Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6430bb",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb87cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hierarchical_clustering(X, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Apply hierarchical clustering and visualize dendrogram\n",
    "    \"\"\"\n",
    "    # Compute linkage matrix\n",
    "    Z = linkage(X, method='ward')\n",
    "    \n",
    "    # Plot dendrogram\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    dendrogram(Z)\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.axhline(y=15, c='k', linestyle='--', label='Cut-off for {} clusters'.format(n_clusters))\n",
    "    plt.legend()\n",
    "    \n",
    "    # Apply clustering with the chosen number of clusters\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    labels = clustering.fit_predict(X)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    sil_score = silhouette_score(X, labels)\n",
    "    print(f\"Silhouette Score for Hierarchical Clustering: {sil_score:.3f}\")\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bdeaae",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans_clustering(X, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Apply K-means clustering and determine optimal k using elbow method\n",
    "    \"\"\"\n",
    "    # Elbow method to find optimal k\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    k_range = range(2, max_clusters + 1)\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        sil_score = silhouette_score(X, labels)\n",
    "        silhouette_scores.append(sil_score)\n",
    "    \n",
    "    # Plot elbow method results\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(k_range, inertias, 'o-')\n",
    "    plt.title('Elbow Method for K-means')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Inertia')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(k_range, silhouette_scores, 'o-')\n",
    "    plt.title('Silhouette Scores for K-means')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Choose optimal k based on silhouette scores\n",
    "    optimal_k = k_range[silhouette_scores.index(max(silhouette_scores))]\n",
    "    print(f\"Optimal number of clusters based on silhouette score: {optimal_k}\")\n",
    "    \n",
    "    # Apply K-means with optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    return labels, kmeans.cluster_centers_, optimal_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625ee76",
   "metadata": {},
   "source": [
    "### GMM Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gmm_clustering(X, max_components=10):\n",
    "    \"\"\"\n",
    "    Apply Gaussian Mixture Model clustering\n",
    "    \"\"\"\n",
    "    # Find optimal number of components using BIC\n",
    "    bic_scores = []\n",
    "    n_components_range = range(1, max_components + 1)\n",
    "    \n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "        gmm.fit(X)\n",
    "        bic_scores.append(gmm.bic(X))\n",
    "    \n",
    "    # Plot BIC scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(n_components_range, bic_scores, 'o-')\n",
    "    plt.title('BIC Scores for different numbers of GMM components')\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('BIC Score')\n",
    "    \n",
    "    # Choose optimal number of components based on BIC\n",
    "    optimal_components = n_components_range[bic_scores.index(min(bic_scores))]\n",
    "    print(f\"Optimal number of GMM components based on BIC: {optimal_components}\")\n",
    "    \n",
    "    # Apply GMM with optimal number of components\n",
    "    gmm = GaussianMixture(n_components=optimal_components, random_state=42)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    \n",
    "    return labels, gmm.means_, optimal_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f34b80",
   "metadata": {},
   "source": [
    "### DBScan Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c649f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dbscan(X):\n",
    "    \"\"\"\n",
    "    Apply DBSCAN clustering to identify outliers and natural clusters\n",
    "    \"\"\"\n",
    "    # Estimate epsilon using nearest neighbors\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=2)\n",
    "    nbrs = nn.fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    distances = np.sort(distances[:, 1])\n",
    "    \n",
    "    # Plot k-distance graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(distances)\n",
    "    plt.title('K-distance Graph')\n",
    "    plt.xlabel('Points sorted by distance')\n",
    "    plt.ylabel('Distance to 2nd nearest neighbor')\n",
    "    \n",
    "    # Choose epsilon from the elbow in the k-distance graph (for demonstration, we'll use a heuristic)\n",
    "    epsilon = np.percentile(distances, 90) * 0.5\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=epsilon, min_samples=3)\n",
    "    labels = dbscan.fit_predict(X)\n",
    "    \n",
    "    # Count number of clusters and noise points\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    \n",
    "    print(f\"Number of clusters: {n_clusters}\")\n",
    "    print(f\"Number of noise points: {n_noise}\")\n",
    "    \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab6b96",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f971af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters_2d(X, labels, centers=None, method_name=\"\"):\n",
    "    \"\"\"\n",
    "    Visualize clusters in 2D using PCA or UMAP\n",
    "    \"\"\"\n",
    "    # Apply dimensionality reduction\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    \n",
    "    # PCA plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', alpha=0.7)\n",
    "    if centers is not None:\n",
    "        centers_pca = pca.transform(centers)\n",
    "        plt.scatter(centers_pca[:, 0], centers_pca[:, 1], c='red', s=100, marker='X')\n",
    "    plt.title(f'PCA Visualization of {method_name} Clusters')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_clusters(df, labels, feature_cols):\n",
    "    \"\"\"\n",
    "    Analyze and interpret the resulting clusters\n",
    "    \"\"\"\n",
    "    # Add cluster labels to the original dataframe\n",
    "    df['cluster'] = labels\n",
    "    \n",
    "    # Calculate cluster statistics\n",
    "    cluster_stats = df.groupby('cluster')[feature_cols].mean()\n",
    "    \n",
    "    # Plot heatmap of cluster characteristics\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(cluster_stats, cmap='coolwarm', center=0, annot=True, fmt='.2f')\n",
    "    plt.title('Cluster Characteristics')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create radar plots for each cluster\n",
    "    n_clusters = len(cluster_stats)\n",
    "    n_features = len(feature_cols)\n",
    "    \n",
    "    # Normalize the features for radar plot\n",
    "    scaler = StandardScaler()\n",
    "    cluster_stats_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(cluster_stats),\n",
    "        index=cluster_stats.index,\n",
    "        columns=cluster_stats.columns\n",
    "    )\n",
    "    \n",
    "    # Create radar plot\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    theta = np.linspace(0, 2*np.pi, n_features, endpoint=False)\n",
    "    theta = np.concatenate((theta, [theta[0]]))  # Close the loop\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        values = cluster_stats_scaled.iloc[i].values\n",
    "        values = np.concatenate((values, [values[0]]))  # Close the loop\n",
    "        \n",
    "        ax = fig.add_subplot(2, (n_clusters+1)//2, i+1, polar=True)\n",
    "        ax.plot(theta, values)\n",
    "        ax.fill(theta, values, alpha=0.25)\n",
    "        ax.set_xticks(theta[:-1])\n",
    "        ax.set_xticklabels(feature_cols, size=8)\n",
    "        ax.set_title(f'Cluster {i}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return cluster_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
